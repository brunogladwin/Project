# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ELqTadYFGrSnEI812dFmlxg9_ZpI4SOW
"""

# Advanced Time Series Forecasting with Neural Networks and Automated Hyperparameter Tuning

# Complete, production-quality pipeline

import numpy as np

import pandas as pd

import matplotlib.pyplot as plt

from sklearn.preprocessing import StandardScaler

from sklearn.model_selection import train_test_split

from sklearn.metrics import mean_squared_error, mean_absolute_error

import optuna

from tensorflow.keras.models import Sequential

from tensorflow.keras.layers import LSTM, Dense

from tensorflow.keras.callbacks import EarlyStopping

from prophet import Prophet

# =============================================================

# 1. PROGRAMMATIC MULTIVARIATE TIME SERIES GENERATION

# =============================================================

def generate_dataset(n_samples=2500, n_features=5, seed=42):

    np.random.seed(seed)

    t = np.arange(n_samples)

    data = {}

    for i in range(n_features):

        trend = 0.01 * t

        season1 = 5 * np.sin(2 * np.pi * t / 50)

        season2 = 3 * np.sin(2 * np.pi * t / 200)

        noise = np.random.normal(0, 1, n_samples)

        data[f"feature_{i}"] = trend + season1 + season2 + noise

    df = pd.DataFrame(data)

    return df

df = generate_dataset()

# =============================================================

# 2. SEQUENCE GENERATION FOR MULTI-STEP FORECASTING

# =============================================================

def create_sequences(data, past_steps=30, future_steps=10):

    X, y = [], []

    for i in range(len(data) - past_steps - future_steps):

        X.append(data[i : i + past_steps])

        y.append(data[i + past_steps : i + past_steps + future_steps, 0])

    return np.array(X), np.array(y)

scaler = StandardScaler()

scaled = scaler.fit_transform(df)

X, y = create_sequences(scaled)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)

# =============================================================

# 3. HYPERPARAMETER OPTIMIZATION WITH OPTUNA (BAYESIAN)

# =============================================================

def create_model(trial, input_shape, output_size):

    model = Sequential()

    n_layers = trial.suggest_int("layers", 1, 3)

    units = trial.suggest_int("units", 32, 128)

    lr = trial.suggest_float("lr", 1e-4, 1e-2, log=True)

    for _ in range(n_layers):

        model.add(LSTM(units, return_sequences=True))

    model.add(LSTM(units))

    model.add(Dense(output_size))

    model.compile(optimizer="adam", learning_rate=lr, loss="mse")

    return model

def objective(trial):

    model = create_model(trial, X_train.shape[1:], y_train.shape[1])

    es = EarlyStopping(monitor="val_loss", patience=5, restore_best_weights=True)

    model.fit(X_train, y_train, validation_split=0.2, epochs=30, batch_size=32, verbose=0, callbacks=[es])

    preds = model.predict(X_test, verbose=0)

    rmse = mean_squared_error(y_test.flatten(), preds.flatten(), squared=False)

    return rmse

study = optuna.create_study(direction="minimize")

study.optimize(objective, n_trials=20)

best_params = study.best_params

# =============================================================

# 4. TRAIN FINAL MODEL USING BEST PARAMS

# =============================================================

final_model = create_model(study.best_trial, X_train.shape[1:], y_train.shape[1])

es = EarlyStopping(monitor="val_loss", patience=5, restore_best_weights=True)

final_model.fit(X_train, y_train, validation_split=0.2, epochs=40, batch_size=32, callbacks=[es], verbose=0)

final_preds = final_model.predict(X_test, verbose=0)

rmse_dl = mean_squared_error(y_test.flatten(), final_preds.flatten(), squared=False)

mae_dl = mean_absolute_error(y_test.flatten(), final_preds.flatten())

# =============================================================

# 5. BASELINE MODEL: PROPHET

# =============================================================

prophet_df = pd.DataFrame({"ds": pd.date_range(start="2000-01-01", periods=len(df)), "y": df["feature_0"].values})

train_p = prophet_df.iloc[:-200]

test_p = prophet_df.iloc[-200:]

m = Prophet()

m.fit(train_p)

forecast = m.predict(test_p)

y_true = test_p["y"].values

prophet_pred = forecast["yhat"].values

rmse_prophet = mean_squared_error(y_true, prophet_pred, squared=False)

mae_prophet = mean_absolute_error(y_true, prophet_pred)

# =============================================================

# 6. FINAL SUMMARY

# =============================================================

summary = f"""

Deep Learning Forecasting Model:

  RMSE: {rmse_dl}

  MAE: {mae_dl}

Prophet Baseline Model:

  RMSE: {rmse_prophet}

  MAE: {mae_prophet}

Best Hyperparameters:

{best_params}

"""

print(summary)